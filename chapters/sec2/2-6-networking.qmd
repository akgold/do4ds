# Intro to Computer Networks {#sec-basic-networks}

If you've got a server but no one can access it, is it really even
there?

If it's in the cloud, yes, you will still get charged for it running.
But it won't be useful.

*Computer networking* -- the subject of how computers send information
back and forth -- is the second big part of administering a server. Once
you've got the server up and running with the applications you want, you
need to make it accessible to the people who need it. That means what
you mostly need to understand is how network traffic gets to the right
place, and what might go wrong to cause that not to function.

In this chapter, you'll learn about the basics of how computer networks
work and how one computer successfully sends a message to another. In
the lab, you'll get to finally make your data science workbench
available on the actual internet.

Let's talk about the mail. The real kind that goes in an envelope and is
delivered in trucks.

When you want to send a letter, you need to use a valid envelope. You
need to address the letter properly and apply a stamp in the right
place.

The same is true of digital traffic. While the envelope, stamp, and
address are all digital, there are shared rules that define what makes
an address or envelope valid. In networking terms, these rules are
called *protocols*. These days, pretty much all computer networking is
accomplished with a stack of protocols called *Transmission Control
Protocol/Internet Protocol (TCP/IP)* stack of protocols.

TCP/IP defines all kinds of things about network traffic, from the
digital equivalent of what a valid envelope size is to how to load and
unload the trucks carrying the mail. But since we're taking advantage of
cloud servers, we really don't need to worry about all that.

Instead, the big topic we need to think about is addresses. It's
important to understand what constitutes a valid digital address, how a
network knows where to route traffic, and what happens when it gets
there.

## Understanding digital addresses

To make things a little more concrete, let's think about the server
we're setting up in the lab. We've got a server running four different
services -- JupyterHub, RStudio Server, the penguin model API, and our
Shiny app.

A mental model I find helpful is to think of our server as like an
apartment building. Each service lives in one apartment and is waiting
for incoming mail. We, as the server admin, are responsible for properly
configuring the incoming traffic to make sure it can get to where it's
going.

You already use digital addresses all the time in the form of the
*Uniform Resource Locator (URL)*.[^2-6-networking-1] A URL fully
specifies the network location of a resource and looks like this:

[^2-6-networking-1]: URLs are a subset of a broader category called
    *Uniform Resource Identifiers (URIs)*, which look like a URL and are
    used to **identify** a resource by may not be a valid address. I
    mention them only because you may run across them in certain
    contexts, like configuring SSO.

$$\overbrace{\text{https://}}^\text{protocol}\underbrace{\text{google.com}}_\text{domain}\overbrace{\text{:443}}^\text{port}\underbrace{\text{/}}_\text{path}$$

You're probably used to just using the domain to access
$\text{google.com}$ or maybe a domain with a path if you're going to
$\text{google.com/maps}$. But the full URL always includes these four
parts.[^2-6-networking-2] It's just that you're usually fine with the
default protocol and port, so you almost never think about them.

[^2-6-networking-2]: Different resources divide URLs into somewhere
    between three and seven parts. I think these four are the most
    useful for this chapter's purpose.

But here's what each of those four parts are:

-   The *application layer protocol* (often just called the protocol)
    specifies what type of traffic this is. It's like agreeing that your
    letter will be in English or Arabic or Dutch.

-   The *domain* is a human-readable way of providing the digital street
    address of the server. We'll get into the actual address later in
    the chapter.

-   The *port* specifies where on the server to direct the traffic. It's
    the digital equivalent of the apartment number.

-   The *path* is a human-friendly way of specifying who you intend the
    message to go to. It's like the name of the entity you're addressing
    on your letter.

The reason that you never think about protocols or ports is that web
traffic is HTTP or HTTPS and use the default ports for HTTP and
HTTPS.[^2-6-networking-3]

[^2-6-networking-3]: These days, it's actually HTTPS. We'll get into
    that in [Chapter @sec-ssl].

The main task of the server admin is to make sure that these defaults
correctly -- and securely -- translate into the services people are
actually trying to access.

## How the traffic arrives

A domain is the human-readable way of addressing a resource on the
internet. But it's not actually the digital street address of any
particular server (host).

Instead, hosts are actually identified with an *IP Address*, which is
mapped to the domain via the *Domain Name Service (DNS)*, which you'll
learn about in [Chapter @sec-dns]. When that IP address is valid across
the entire internet, it's a *public* IP address.

When traffic is created, it's chopped up into parts called *packets*.
Those packets are then routed to the correct IP address in a process
called *packet switching*.[^2-6-networking-4]

[^2-6-networking-4]: How packet switching works isn't super relevant,
    but it is cool. Packets are addressed with their target IP address
    when they're first created and are passed off to the router to which
    the computer is connected. Routers are arranged in a tree-style
    hierarchy. What's clever is that each router **only** keeps track of
    downstream addresses and a single upstream *default address*. So the
    packet gets passed upstream until it hits a router that knows about
    the target IP address and then back downstream to the host.

Once the traffic arrives at the server, it has to get to the right
service. Services are mapped 1-1 to open ports. Every computer has just
over 65,000 ports. Each port is uniquely identified by a number, and
there's a 1-1 mapping between listening services and open ports. Since
you're probably running no more than a handful of services, the
overwhelming majority of the ports are closed at any given
time.[^2-6-networking-5]

[^2-6-networking-5]: Ports are also used for outbound communication.
    Computers know how to automatically open ports for outbound
    communication and specify that's where the response should come, so
    we're not going to get into them here.

By default, HTTP traffic goes to port $80$ and HTTPS traffic goes to
port $443$.

So if there's just one thing on the server, you would configure the
application to put itself on port $80$ and/or $443$. Then, when people
come to the root of the domain, they'd automatically get to the right
service.

But sometimes you've got multiple services on the server. In that case,
each one will need to run on a unique port and you can map those ports
to subpaths using a *proxy*. Common proxies you might hear about include
the open source *Nginx* and *Apache* and the paid *F5*, who also develop
NGINX. Depending on the configuration, the proxy can be on the same
server or a different one.

If you're using a proxy, you'd put each of the server's services on a
different port and use the proxy to redirect incoming traffic to the
right place based on the subpath.

![](images/firewall-proxy.png){fig-alt="Traffic coming through firewall only on port 80. Proxy routes /jupyter to port 8000 on server and /rstudio to port 8787."
width="600"}

Now, if you were just to put something on port $80$ on your EC2 instance
and try to access it from the web at the public IP address, it still
wouldn't work. That's because an EC2 instance, comes with a built in
*firewall*, which blocks traffic to all but certain ports. In AWS, it's
called the *security group*.

::: callout-tip
If you think you've configured a service correctly and you just can't
seem to access it, one of the first things to check is whether you've
got the port open in the security group.

One symptom that may indicate a security group issue is if you try to go
to your service and it just hangs with no response before eventually
timing out.
:::

Once the traffic makes it to the right server, through the firewall and
proxy, and to the right port, it has to communicate using the right
application layer protocol. We've been talking exclusively about the
HTTP and HTTPS application layer protocols, because web traffic arrives
as a series of HTTP `GET` requests, but there are many other application
layer protocols, each with its own default port.

For example, you've already seen a lot about SSH in this book, which is
an application layer protocol for allowing secure login and
communication over an unsecured network. SSH defaults to port $22$.

Other important protocols that you might see in this book or elsewhere
are SFTP for file transfers, SMTP for emails, LDAP(S) for auth, and
websockets, which are used by Shiny and Streamlit.

## Recognizing IP addresses

If you've seen an IP address before, it probably was an *IPv4*
*address*, which are four blocks of 8-bit fields (numbers between $0$
and $255$) with dots in between, so they look like $64.56.223.5$.

If you do the math, you'll realize there are "only" about 4 billion of
these. There are so many things on the public internet that we are
running out of IPv4 addresses.

The good news is that smart people started planning for this a while ago
and the adoption of the new *IPv6* standard started a few years ago.

IPv6 addresses are eight blocks of hexadecimal ($\text{0-9}$ and
$\text{a-f}$) digits separated by colons, with certain rules that allow
them to be shortened, so
$\text{4b01:0db8:85a3:0000:0000:8a2e:0370:7334}$ or $\text{3da4:66a::1}$
are both examples of valid IPv6 addresses. There's no worry about
running out of IPv6 addresses any time soon, because the total quantity
of IPv6 addresses is a number with 39 zeroes.

IPv6 will coexist with IPv4 for a few decades and we'll eventually
switch entirely to IPv6.

There are a few special IPv4 addresses it's worth knowing. You'll
probably see $127.0.0.1$ a lot, which is also known as
$\text{localhost}$ or loopback. This is the way a machine refers to
itself.

For example, if you open a Shiny app in RStudio Desktop, the app will
pop up in a little window along with a notice that says

```{bash}
Listening on http://127.0.0.1:6311
```

That means that the Shiny app is running on the same computer and is
available on port $6311$.

There are also a few blocks of IPv4 addresses -- those that start with
$192.168$, $172.16$, and $10$ that are reserved for use on private
networks, so they're never assigned in public.

## Basic network administration

Networking can be difficult to manage because there are so many layers.
It will frequently happen that you think a service is configured, but
you just can't seem to access it. Here are some basic tools for network
debugging.

### Browser devtools

One of the most useful tools for debugging networking issues can be
found right in your browser. Your browser has developer tools that allow
you to inspect the network traffic going back and forth between your
machine and a remote.

This can be really handy if things are going slowly or if you're not
sure why the page isn't loading. By inspecting the status codes of
different HTTP calls and the time they take, you can develop a pretty
good idea of where things might be getting stuck.

### SSH tunneling/port forwarding

When you start a new EC2 instance in AWS, the default security group
opens only port $22$ to allow SSH inbound.

So far, you've seen SSH used to access the command line on that remote
server, but SSH can actually be used to access any port in a process
called *tunneling* or *port forwarding*.

When you tunnel, you make a port on the remote host available at the
same port on $\text{localhost}$ on your local machine. The most common
usage is to use your browser to look send traffic to a specific port on
a remote host without configuring the host to accept HTTP traffic on
that port.

You can create an SSH tunnel to a remote host with

```{ssh -L <remote port>:localhost:<local port> <user>@<server>}
```

I find that the syntax for port forwarding completely defies my memory
and I have to google it every time I use it.[^2-6-networking-6]

[^2-6-networking-6]: As you might guess from this complicated syntax,
    you can do a lot more than this with SSH tunneling, but this is most
    often what I use it for.

So, for example, if your server were running at $64.56.223.5$ and you
has the SSH user `test-user`, you might forward JupyterHub on port
$8000$ with `ssh -L 8000:localhost:8000 test-user@64.56.223.5`. Once the
tunnel is established, you could access JupyerHub on
$\text{localhost:8000}$.

### Checking ports

Sometimes you can just forget what ports are open on your machine and
for what purposes. Or you want to double check that a configuration
change took. In that case, you want to use the `netstat` command to get
the services that are running and their associated ports.

For this use, `netstat` is generally most useful with the `-tlp` flags
to show programs that are listening and the programs associated.

### Checking if a host is accessible

The `ping` command can be useful for checking whether your server is
reachable on the network. For example, the server where this book lives
is at $185.199.110.153$. So I can ping that domain to check if it's
accessible.

``` bash
> ping -o 185.199.110.153

PING 185.199.110.153 (185.199.110.153): 56 data bytes
64 bytes from 185.199.110.153: icmp_seq=0 ttl=58 time=23.322 ms

--- 185.199.110.153 ping statistics ---
1 packets transmitted, 1 packets received, 0.0% packet loss
round-trip min/avg/max/stddev = 23.322/23.322/23.322/nan ms
```

The `-o` flag tells `ping` to try just once as opposed to pinging
continuously. The fact that I transmitted and received one packet means
that everything is working properly.

Seeing an unreachable host or packet loss would be an indication that my
networking probably isn't configured correctly somewhere between me and
the server.

If `ping` fails, it means that the server isn't reachable and it's time
to check firewalls (security groups) and proxies. You can also use ping
with a domain, so it can also be used to see if DNS is working properly.

If `ping` succeeds but the particular resource is inaccessible, `curl`
is can be a useful command. `curl` actually attempts to fetch the
website at a particular URL. It's often useful to use `curl` with the
`-I` option so it just returns a simple status report, not the full
contents of what it finds there.

For example, here's what I get when I `curl` the website for this book.

``` bash
> curl -I https://do4ds.com                                         

HTTP/2 200
server: GitHub.com
content-type: text/html; charset=utf-8
last-modified: Tue, 04 Jul 2023 16:23:38 GMT
access-control-allow-origin: *
etag: "64a4478a-79cb"
...
```

The important thing here is that first line. The server is returning a
`200` HTTP status code, which means all is well. If you get something
else, take a look at the http code cheatsheet in [Appendix
@sec-append-cheat].

If `ping` succeeds, but `curl` does not, it means that the server is up,
but the path or port is incorrect. If you're running inside a container,
you should check that you've properly configured the port inside
container to be forwarded to the outside.

## Comprehension Questions

1.  What are the 4 components of a URL? What's the significance of each?
2.  Are there any inherent differences between public and private IP
    addresses?
3.  Draw a mind map of trying to access the following in your browser.
    Include the following terms: URL, domain, IP Address, port, path,
    $80$, $443$, `8000`, proxy, server, HTTP, HTTPS, status code,
    protocol
    1.  A Shiny app on a server at $\text{http://my-shiny.com}$ where
        Shiny Server is sitting on port $80$.
    2.  JupyterHub on a server at $\text{https://example.com/jupyter}$
        where Jupyter is on port `8000`.

## Lab: Making it accessible in one place

In this lab, we're going to set up a proxy to be able to access all of
our services over HTTP(S).

But first, you might want to try out accessing the various services
where they are.

You could either try SSH tunneling to them and seeing them on localhost
or you could apply custom TCP rules to your security group to
temporarily allow access directly to the services. If you want to try,
here's a reminder of where everything is:

| Service           | Port   |
|-------------------|--------|
| JupyterHub        | $8000$ |
| RStudio           | $8787$ |
| Penguin model API | $8080$ |
| Shiny App         | $3838$ |

If you're through playing and ready to get everything configured, let's
go ahead.

### Step 1: Configure Nginx

Honestly, configuring proxies is a somewhat advanced networking topic,
and in most cases you'd just put one service per server. But if you want
to be able to save money and run everything on one server, you'll want a
proxy.

Configuring Nginx is pretty straightforward -- you install Nginx, put
the configuration file into place, and restart the service to pick up
the changes. The hard part is figuring out the right configuration.
Configuring proxies can be quite painful, as the configuration is very
sensitive to seemingly meaningless syntax issues.

Here are the steps to configure your proxy on your server for JupyterHub
and RStudio Server:

1.  SSH into your server.
2.  Install Nginx with `sudo apt install nginx`.
3.  Save a backup of the default `nginx.conf`,
    `cp /etc/nginx/nginx.conf /etc/nginx/nginx-backup.conf`.[^2-6-networking-7]
4.  Edit the Nginx configuration with `sudo vim /etc/nginx/nginx.conf`
    and replace it with:

[^2-6-networking-7]: This is generally a good practice before you start
    messing with config files. Bad configuration is usually preferable
    to a service that can't start at all because you've messed up the
    config so badly. It happens.

``` {.bash include="../../_labs/server-config/http-nginx.conf" filename="/etc/nginx/nginx.conf"}
```

4.  Test that your configuration is valid `sudo nginx -t`.
5.  Start Nginx with `sudo systemctl start nginx`. If you see nothing
    all is well.

If you need to change anything, update the config and then restart with
`sudo systemctl restart nginx`.

### Step 2: Open port 80

Now, if you try to go to your your server's public IP address or DNS,
your browser will spin for a while and nothing will happen. That's
because the AWS security group still only allows SSH access on port
$22$. We need to add a rule that will allow HTTP access on port $80$.

On the AWS console page for your instance, find the Security section and
click into the security group for your instance. You want to add a new
inbound HTTP rule that allows access on port $80$ from anywhere. Make
sure not to get rid of the rule that allows SSH access on $22$. You
still need that one too.

Once you do this, you should be able to visit your server address and
get the default Nginx landing page.

### Step 3: Configure your subpaths

Complex web apps like RStudio and JupyterHub frequently proxy traffic
back to themselves. For example, when you launch a Shiny app in RStudio,
you're actually just opening a "headless" browser window that gets
proxied back into your session.

This works by default when those apps are on the root path $\text{/}$.
That's not true in this case, so we've got to let the services know
where they're actually located.

Configuring RStudio Server is already done. The `X-RStudio-Root-Path`
line in the Nginx configuration adds a header to each request coming
through the proxy that tells RStudio Server that it's on the
$\text{/rstudio}$ path.

JupyterHub needs a configuration update to let it know that it's on a
subpath. Luckily it's a very simple change. You can edit the Jupyter
configuration with

``` {.bash filename="Terminal"}
sudo vim /etc/jupyterhub/jupyterhub_config.py
```

Find the line that reads `# c.JupyterHub.bind_url = 'http://:8000'`.

::: callout-tip
You can search in vim from normal mode with
`/ <thing you're searching for>`. Go to the next hit with `n`.
:::

Delete the `#` to uncomment the line and add the subpath on the end. If
you're using the $\text{/jupyter}$ subpath and the default `8000` port,
that line will read `c.JupyterHub.bind_url = 'http://:8000/jupyter'`.

JupyterHub should pick up the new config when it's restarted with

``` {.bash filename="Terminal"}
sudo systemctl restart jupyterhub
```

### Step 4: Try it out!

Now we should have each service configured on a subpath. RStudio Server
at $\text{/rstudio}$, JupyterHub at $\text{/jupyter}$, and our machine
learning API at $/text{/penguins}$. For example, with my server at
$/text{64.56.223.5}$, I can get to RStudio Server at
$/text{http://64.56.223.5/rstudio}$.

Note that right now, this server is on HTTP, which is not a best
practice. In fact, it's such a bad practice that your browser will
probably autocorrect the url to `https`. You'll have to manually correct
it to `http`.

### Lab Extensions

If you've gone to the bare URL for your server, you've probably noticed
that it's just the default Nginx landing page, which is not very
attractive.

You might want to create a landing page with links to the subpath by
serving a static html page off of $\text{/}$. Or maybe you want one of
the services at $\text{/}$ and the others at a different subpath.

Right now, neither the penguins model API or the Shiny app are available
from the outside. You might want to add them to the proxy to make them
accessible. I'll leave that as an exercise for you.

::: callout-tip
It's very common to put an API and/or a Shiny app behind a proxy.
Googling "Shiny app behind nginx" or "FastAPI with nginx" will yield
good results.
:::

One thing to consider is whether the model API should be publicly
accessible at all. If the only thing calling it is the Shiny app, maybe
it shouldn't be?

