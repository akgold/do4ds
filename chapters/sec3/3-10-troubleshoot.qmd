# Basic Troubleshooting and Debugging {#sec-troubleshoot}

If things are going poorly on your server, here are some steps you might
take to try to troubleshoot.

### Check storage usage

A common culprit for weird server behavior is running out of storage
space. There are two handy commands for monitoring the amount of storage
you've got -- `du` and `df`. These commands are almost always used with
the `-h` flag to put file sizes in human-readable formats.

`df`, for disk free, shows the capacity left on the device where the
directory sits.

For example, here's the result of running the `df` command on the
chapters directory on my laptop that includes this chapter.

``` bash
 ❯ df -h chapters                                                    
Filesystem     Size   Used  Avail Capacity iused      ifree %iused  Mounted on
/dev/disk3s5  926Gi  163Gi  750Gi    18% 1205880 7863468480    0%   /System/Volumes/Data
```

So you can see that the chapters folder lives on a disk called
`/dev/disk3s5` that's a little less than 1Tb and is 18% full -- no
problem. On a server this can be really useful to know, because it's
quite easy to switch a disk out for a bigger one in the same spot.

If you've figured out that a disk is full and need to figure out where
the culprits are, the `du` can be useful. `du`, short for disk usage,
gives you the size of individual files inside a directory. It's
particularly useful in combination with the `sort` command.

For example, here's the result of running `du` on the `chapters`
directory where the text files for this book live.

``` bash
 ❯ du -h chapters | sort -h                                      
 44K    chapters/sec2/images-servers
124K    chapters/sec3/images-scaling
156K    chapters/sec2/images
428K    chapters/sec2/images-traffic
656K    chapters/sec1/images-code-promotion
664K    chapters/sec1/images-docker
1.9M    chapters/sec1/images-repro
3.4M    chapters/sec1
3.9M    chapters/sec3/images-auth
4.1M    chapters/sec3
4.5M    chapters/sec2/images-networking
5.3M    chapters/sec2
 13M    chapters
```

So if I were thinking about cleaning up this directory, I could see that
my `images-networking` directory in `sec2` is the biggest single
bottom-level directory. If you find yourself needing to find big files
on your Linux server, it's worth spending some time with the help pages
for `du`. There are lots of really useful options.

`du` is useful for identifying large files and directories on a server.

### Look at what's running

A running program is a *process*. For example, when you type `python` on
the command line to open a REPL, that starts a single Python process. If
you were to start a second terminal session and run `python` again,
you'd have a second Python process.

Complicated programs often involves multiple than one process. For
example, running the RStudio IDE involves (at minimum) one process for
the IDE itself and one for the R session that it uses in the background.
The relationships between these different processes is mostly hidden
from you -- the end user.

As a server admin, finding runaway processes, killing them, and figuring
out how to prevent the them from happening again is a pretty common
task. Runaway processes usually misbehave by using up the entire CPU or
filling up the entire machine's RAM.

Like users and groups have ids, each process has a numeric process id
(`pid`). Each process also has an owner -- this can be either a service
account or a real user. If you've got a rogue process, the pattern is to
try to find the process and make note of its `pid`. Then you can
immediately end the process by `pid` with the `kill` command.

So, how do you find a troublesome process?

The `top` command is a good first stop. `top` shows the top
CPU-consuming processes in real time. Here's the `top` output from my
machine as I write this sentence.

``` bash
PID    COMMAND      %CPU TIME     #TH    #WQ  #PORT MEM    PURG   CMPRS PGRP
0      kernel_task  16.1 03:56:53 530/10 0    0     2272K  0B     0B    0
16329  WindowServer 16.0 01:53:20 23     6    3717  941M-  16M+   124M  16329
24484  iTerm2       11.3 00:38.20 5      2    266-  71M-   128K   18M-  24484
29519  top          9.7  00:04.30 1/1    0    36    9729K  0B     0B    29519
16795  Magnet       3.1  00:39.16 3      1    206   82M    0B     39M   16795
16934  Arc          1.8  18:18.49 45     6    938   310M   144K   61M   16934
16456  Messages     1.7  06:58.27 4      1    603   138M   2752K  63M   16456
1      launchd      1.7  13:41.03 4/1    3/1  3394+ 29M    0B     6080K 1
573    diagnosticd  1.4  04:31.97 3      2    49    2417K  0B     816K  573
16459  zoom.us      1.3  66:38.37 30     3    2148  214M   384K   125M  16459
16575  UniversalCon 1.3  01:15.89 2      1    131   12M    0B     2704K 16575
```

In most instances, the first three columns are the most useful. You've
got the name of the process (`COMMAND`) and how much CPU its using.
Right now, nothing is using very much CPU. If I were to find something
concerning -- perhaps an R process that is using 500% of CPU -- I would
want to take notice of its `pid` to kill it with `kill`.

::: callout-note
### So much CPU?

For `top` (and most other commands), CPU is expressed as a percent of
*single core* availability. So, on a modern machine with multiple cores,
it's very common to see CPU totals well over 100%. Seeing a single
process using over 100% of CPU is rarer.
:::

The `top` command takes over your whole terminal. You can exit with
`Ctrl + c`.

Another useful command for finding runaway processes is `ps aux`. It
lists a snapshot of all processes running on the system, along with how
much CPU and RAM they're using. You can sort the output with the
`--sort` flag and specify sorting by cpu with `--sort -%cpu` or by
memory with `--sort -%mem`.

Because `ps aux` returns *every* running process on the system, you'll
probably want to pipe the output into `head`.

Another useful way to use `ps aux` is in combination with `grep`. If you
pretty much know what the problem is -- often this might be a runaway R
or Python process -- `ps aux | grep <name>` can be super useful to get
the `pid`.

For example, here are the RStudio processes currently running on my
system.[^3-5-app-admin-1]

[^3-5-app-admin-1]: This command actually cuts off the header line of
    the table. What I actually ran was `ps aux | grep "RStudio\|USER"`.

``` bash
 > ps aux | grep "RStudio"                                                                                      [10:21:18]
USER               PID  %CPU %MEM      VSZ    RSS   TT  STAT STARTED      TIME COMMAND
alexkgold        23583   0.9  1.7 37513368 564880   ??  S    Sat09AM  17:15.27 /Applications/RStudio.app/Contents/MacOS/RStudio
alexkgold        23605   0.5  0.4 36134976 150828   ??  S    Sat09AM   1:58.16 /Applications/RStudio.app/Contents/MacOS/rsession --config-file none --program-mode desktop 
```

### Make sure the right ports are open

Networking is a complicated topic, which we'll approach with great
detail in [Chapter @sec-basic-networks]. Most often, you'll want to
check that the application you're running is actually accessible to the
outside world, assuming you want it to be.

The main command to help you see what ports are being used and by what
services is the `netstat` command. `netstat` returns the services that
are running and their associated ports. `netstat` is generally most
useful with the `-tlp` flags to show programs that are listening and the
programs associated.

Sometimes you *know* you've got a service running on your machine, but
you just can't seem to get the networking working. It can be useful to
access the service directly without having to deal with networking.

SSH port forwarding allows you to take the output of a port on a remote
server, route it through SSH, and display it as if it were on a local
port. For example, let's say you've got RStudio Server running on my
server but the web interface isn't working. If you've got SSH working
properly, you can double check that the service is working and the issue
really is networking.

I find that the syntax for port forwarding completely defies my memory
and I have to google it every time I use it. For the kind of port
forwarding you'll use most often in debugging, you'll use the `-L` flag
to get a remote port locally.

`ssh -L <local port>:<remote ip>:<remote port> <ssh hostname>`

The local would be your laptop and the remote your server, so if you had
RStudio Server running on a server on port `3939`. Then you could run
`ssh -L 3939:localhost:3939 my-user@my-ds-workbench.com`. To get
whatever is at port `3939` on the server (hopefully RStudio Workbench!)
by going to `localhost:3939` in the laptop's browser.

Most often, you'll use the same port locally and on the remote and the
remote ip will be `localhost`.

### Check your path

Let's say you want to open Python on your command line. One option would
be to type the complete path to a Python install every time. For
example, I've got a version of Python in `/usr/bin`, so
`/usr/bin/python3` works.

But in most cases, it's nice to just type `python3` and have the right
version open up.

``` bash
$ python3
Python 3.9.6 (default, May  7 2023, 23:32:45) 
[Clang 14.0.3 (clang-1403.0.22.14.1)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> 
```

In some cases, this isn't optional. Certain applications will rely on
others being available, like RStudio needing to find R. Or Jupyter
Notebook finding your Python kernels.

So how does the operating system know where to find those applications
and files?

If you ever want to check which actual executable is being used by a
command, you can use the `which` command. For example, on my system this
is the result of `which python3`.

``` bash
 ❯ which python3                                                    
/usr/bin/python3
```

The operating system knows how to find the actual runnable programs on
your system via the *path*. The path is a set of directories that the
system knows to search when it tries to run a path. The path is stored
in an environment variable conveniently named `PATH`.

You can check your path at any time by echoing the `PATH` environment
variable with `echo $PATH`. On my MacBook, this is what the path looks
like.

``` bash
 ❯ echo $PATH                                                      
/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin
```

When you install a new piece of software you'll need to add it two the
path. Say I was to install a new version of Python in `/opt/python`.
That's not on my `PATH`, so my system wouldn't be able to find it.

I can get it on the path in one of two ways -- the first option would be
to add `/opt/python` to my `PATH` every time a terminal session starts
usually via a file in `/etc` or the `.zshrc`. The other option is to
create a *symlink* to the new application in a directory already on the
`PATH`. A symlink does what it sounds like -- creates a way to link to a
file from a different directory without moving it.

Symlinks are created with the `ln` command.

## Comprehension Questions

1.  How would you do the following?
    1.  Find and kill the process IDs for all running `rstudio-server`
        processes.

    2.  Figure out which port `JupyterHub` is running on.

    3.  Create a file called `secrets.txt`, open it with vim, write
        something in, close and save it, and make it so that only you
        can read it.
